{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning TimeSFM con PyTorch + Inferencia de Valor/Volatilidad\n",
    "\n",
    "Este _notebook_ combina:\n",
    "\n",
    "1. **Descarga de datos BTC a 5m** mediante `get_binance_klines(...)`.\n",
    "2. **Creación de dataset** de entrenamiento (train/val) con una clase `TimeSeriesDataset`.\n",
    "3. **Bucle de entrenamiento** (fine-tuning) partiendo del checkpoint genérico `google/timesfm-2.0-500m-pytorch`.\n",
    "4. **Guardado** de un nuevo checkpoint local con los pesos ajustados.\n",
    "5. **Código Flask** (al final) que levanta un servidor y usa el modelo fine-tuneado para inferir valor y volatilidad.\n",
    "\n",
    "De esta manera, podrás **afinar** TimeSFM en tus datos de BTC 5m y luego **servirlo** en tu API.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import logging\n",
    "import traceback\n",
    "from flask import Flask, Response\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import timesfm\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from timesfm import TimesFm, TimesFmCheckpoint, TimesFmHparams\n",
    "from timesfm.pytorch_patched_decoder import PatchedTimeSeriesDecoder\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Este es el checkpoint base en HuggingFace\n",
    "MODEL_REPO = \"google/timesfm-2.0-500m-pytorch\"\n",
    "\n",
    "# Definimos hparams genéricos. Se reescribirá horizon_len cuando sea necesario.\n",
    "tsfm_hparams = TimesFmHparams(\n",
    "    backend=\"pytorch\",\n",
    "    per_core_batch_size=32,\n",
    "    horizon_len=128,        # Se puede sobrescribir\n",
    "    input_patch_len=32,\n",
    "    output_patch_len=128,\n",
    "    num_layers=50,\n",
    "    model_dims=1280,\n",
    "    use_positional_embedding=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Funciones para descargar BTC 5m\n",
    "Usamos las mismas que en tu código:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binance_klines(symbol=\"BTCUSDT\", interval=\"5m\", max_candles=2000):\n",
    "    df_all = pd.DataFrame()\n",
    "    limit = 1000\n",
    "    url = \"https://api.binance.com/api/v3/klines\"\n",
    "    params = {\"symbol\": symbol, \"interval\": interval, \"limit\": limit}\n",
    "    resp = requests.get(url, params=params)\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(str(resp.text))\n",
    "    data = resp.json()\n",
    "    if not data:\n",
    "        raise Exception(\"Empty response\")\n",
    "\n",
    "    cols = [\n",
    "        \"open_time\",\"open\",\"high\",\"low\",\"close\",\"volume\",\n",
    "        \"close_time\",\"quote_asset_volume\",\"number_of_trades\",\n",
    "        \"taker_buy_base_asset_volume\",\"taker_buy_quote_asset_volume\",\"ignore\"\n",
    "    ]\n",
    "    df_part = pd.DataFrame(data, columns=cols)\n",
    "    df_part[\"date\"] = pd.to_datetime(df_part[\"close_time\"], unit=\"ms\")\n",
    "    df_all = pd.concat([df_all, df_part], ignore_index=True)\n",
    "    last_close_time = int(df_part[\"close_time\"].iloc[-1])\n",
    "\n",
    "    while True:\n",
    "        if len(df_all) >= max_candles:\n",
    "            break\n",
    "        time.sleep(0.2)\n",
    "        params = {\n",
    "            \"symbol\": symbol,\n",
    "            \"interval\": interval,\n",
    "            \"limit\": limit,\n",
    "            \"startTime\": last_close_time + 1\n",
    "        }\n",
    "        resp = requests.get(url, params=params)\n",
    "        if resp.status_code != 200:\n",
    "            raise Exception(str(resp.text))\n",
    "        data = resp.json()\n",
    "        if not data:\n",
    "            break\n",
    "        df_part = pd.DataFrame(data, columns=cols)\n",
    "        df_part[\"date\"] = pd.to_datetime(df_part[\"close_time\"], unit=\"ms\")\n",
    "        df_all = pd.concat([df_all, df_part], ignore_index=True)\n",
    "        last_close_time = int(df_part[\"close_time\"].iloc[-1])\n",
    "        if len(df_part) < limit:\n",
    "            break\n",
    "\n",
    "    float_cols = [\n",
    "        \"open\",\"high\",\"low\",\"close\",\"volume\",\"quote_asset_volume\",\n",
    "        \"taker_buy_base_asset_volume\",\"taker_buy_quote_asset_volume\"\n",
    "    ]\n",
    "    for c in float_cols:\n",
    "        df_all[c] = df_all[c].astype(float)\n",
    "\n",
    "    df_all.sort_values(\"date\", inplace=True)\n",
    "    df_all.reset_index(drop=True, inplace=True)\n",
    "    return df_all\n",
    "\n",
    "def get_binance_value_5m(token=\"BTC\"):\n",
    "    if token.upper() != \"BTC\":\n",
    "        raise ValueError(\"Solo BTC en este ejemplo.\")\n",
    "    return get_binance_klines(symbol=\"BTCUSDT\", interval=\"5m\", max_candles=2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Preparamos los datos para *fine-tuning*\n",
    "Queremos entrenar un **modelo univariante** (solo `close`), así que transformaremos a `log_close`. \n",
    "\n",
    "Para el entrenamiento, usaremos una clase `TimeSeriesDataset` que cree ventanas `(x_context, x_future)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"Dataset (train/val) para TimeSFM, usando un array unidimensional log_close.\"\"\"\n",
    "    def __init__(self, series: np.ndarray, context_length: int, horizon_length: int, freq_type: int = 0):\n",
    "        self.series = series\n",
    "        self.context_length = context_length\n",
    "        self.horizon_length = horizon_length\n",
    "        self.freq_type = freq_type\n",
    "        self.samples = []\n",
    "        total_len = context_length + horizon_length\n",
    "\n",
    "        for start_idx in range(len(series) - total_len):\n",
    "            x_cont = series[start_idx : start_idx + context_length]\n",
    "            x_fut  = series[start_idx + context_length : start_idx + total_len]\n",
    "            self.samples.append((x_cont, x_fut))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_cont, x_fut = self.samples[idx]\n",
    "        x_cont = torch.tensor(x_cont, dtype=torch.float32)\n",
    "        x_fut  = torch.tensor(x_fut,  dtype=torch.float32)\n",
    "\n",
    "        input_padding = torch.zeros_like(x_cont)\n",
    "        freq = torch.tensor([self.freq_type], dtype=torch.long)\n",
    "\n",
    "        return x_cont, input_padding, freq, x_fut\n",
    "\n",
    "def create_train_val_datasets(context_len=128, horizon_len=16, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Descarga BTCUSDT 5m, crea log_close y genera dataset train/val\n",
    "    \"\"\"\n",
    "    df = get_binance_klines(\"BTCUSDT\", \"5m\", max_candles=5000)  # si quieres más datos, sube max_candles\n",
    "    df.sort_values(\"date\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Evitamos problemas de 0 en close\n",
    "    df[\"close\"] = df[\"close\"].clip(lower=1e-9)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Tomamos log_close\n",
    "    df[\"log_close\"] = np.log(df[\"close\"])\n",
    "    series_np = df[\"log_close\"].values\n",
    "\n",
    "    split_index = int(len(series_np) * train_split)\n",
    "    train_data = series_np[:split_index]\n",
    "    val_data   = series_np[split_index:]\n",
    "\n",
    "    train_ds = TimeSeriesDataset(train_data, context_len, horizon_len, freq_type=0)\n",
    "    val_ds   = TimeSeriesDataset(val_data,   context_len, horizon_len, freq_type=0)\n",
    "    return train_ds, val_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Creación del modelo base y bucle de entrenamiento\n",
    "Partimos de `google/timesfm-2.0-500m-pytorch` y lo entrenamos en PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timesfm_model(load_pretrained=True, device=\"cuda\"):\n",
    "    # Ajustamos hiperparams\n",
    "    # Se puede reescribir horizon_len luego, esto es un valor 'base'\n",
    "    hparams = TimesFmHparams(\n",
    "        backend=device,\n",
    "        horizon_len=16,  # lo ajustamos a nuestro scenario\n",
    "        input_patch_len=32,\n",
    "        output_patch_len=16,\n",
    "        num_layers=50,\n",
    "        model_dims=1280,\n",
    "        use_positional_embedding=False,\n",
    "    )\n",
    "\n",
    "    if load_pretrained:\n",
    "        checkpoint = TimesFmCheckpoint(huggingface_repo_id=MODEL_REPO)\n",
    "    else:\n",
    "        checkpoint = None\n",
    "\n",
    "    # Creamos un TimesFm\n",
    "    tfm_model = TimesFm(hparams=hparams, checkpoint=checkpoint)\n",
    "\n",
    "    # Extraemos el modelo PyTorch real\n",
    "    pytorch_model = PatchedTimeSeriesDecoder(tfm_model._model_config)\n",
    "    pytorch_model.to(device)\n",
    "\n",
    "    if load_pretrained:\n",
    "        # Cargamos pesos del repo HF\n",
    "        ckpt_path = snapshot_download(MODEL_REPO) + \"/torch_model.ckpt\"\n",
    "        weights = torch.load(ckpt_path, map_location=device)\n",
    "        pytorch_model.load_state_dict(weights, strict=False)\n",
    "\n",
    "    return pytorch_model, hparams\n",
    "\n",
    "def train_loop(model,\n",
    "               train_ds,\n",
    "               val_ds,\n",
    "               epochs=5,\n",
    "               lr=1e-4,\n",
    "               batch_size=32,\n",
    "               device=\"cuda\"):\n",
    "    \"\"\"Bucle sencillo de entrenamiento con MSELoss\"\"\"\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x_cont, x_pad, freq, x_fut in train_loader:\n",
    "            x_cont = x_cont.to(device)\n",
    "            x_pad  = x_pad.to(device)\n",
    "            freq   = freq.to(device)\n",
    "            x_fut  = x_fut.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(x_cont, x_pad, freq)\n",
    "            # preds.shape puede ser [B, N, horizon_len] o [B, N, horizon_len, channels]\n",
    "            # en MSE univariante, nos interesa [B, horizon_len].\n",
    "            if preds.ndim == 4:\n",
    "                # [B, N, horizon_len, 1]\n",
    "                preds = preds[..., 0]\n",
    "            if preds.ndim == 3:\n",
    "                # [B, N, horizon_len]\n",
    "                # Cogemos el último patch\n",
    "                preds = preds[:, -1, :]\n",
    "\n",
    "            loss = criterion(preds, x_fut)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        mean_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_cont, x_pad, freq, x_fut in val_loader:\n",
    "                x_cont = x_cont.to(device)\n",
    "                x_pad  = x_pad.to(device)\n",
    "                freq   = freq.to(device)\n",
    "                x_fut  = x_fut.to(device)\n",
    "                vpreds = model(x_cont, x_pad, freq)\n",
    "                if vpreds.ndim == 4:\n",
    "                    vpreds = vpreds[..., 0]\n",
    "                if vpreds.ndim == 3:\n",
    "                    vpreds = vpreds[:, -1, :]\n",
    "\n",
    "                vloss = criterion(vpreds, x_fut)\n",
    "                total_val_loss += vloss.item()\n",
    "        mean_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs}, train_loss={mean_train_loss:.4f}, val_loss={mean_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Entrenar y guardar un checkpoint local\n",
    "En la siguiente celda, haremos:\n",
    "- Descarga de datos\n",
    "- Creación del dataset `train_ds` y `val_ds` (con `context_len=128` y `horizon_len=16`, por ejemplo)\n",
    "- Creación del modelo base (`load_pretrained=True`)\n",
    "- Llamamos a `train_loop(...)`\n",
    "- Guardamos los pesos finetuneados en un .ckpt local\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_finetuning():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Usando device={device}\")\n",
    "\n",
    "    # Preparamos dataset (BTC 5m)\n",
    "    train_ds, val_ds = create_train_val_datasets(\n",
    "        context_len=128,\n",
    "        horizon_len=16,\n",
    "        train_split=0.8\n",
    "    )\n",
    "    print(f\"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}\")\n",
    "\n",
    "    # Creamos modelo base (preentrenado) + hparams\n",
    "    model, base_hparams = create_timesfm_model(load_pretrained=True, device=device)\n",
    "\n",
    "    # Entrenamos (ejemplo: 5 epochs)\n",
    "    train_loop(\n",
    "        model=model,\n",
    "        train_ds=train_ds,\n",
    "        val_ds=val_ds,\n",
    "        epochs=5,\n",
    "        lr=1e-4,\n",
    "        batch_size=32,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Guardar checkpoint local\n",
    "    ckpt_path = \"my_finetuned_timesfm.ckpt\"\n",
    "    torch.save(model.state_dict(), ckpt_path)\n",
    "    print(f\"\\nCheckpoint guardado en {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes **ejecutar** la celda de arriba para hacer el fine-tuning. Una vez finalice, tendrás un nuevo fichero `my_finetuned_timesfm.ckpt` con tus pesos ajustados."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Descomenta para entrenar:\n",
    "# run_finetuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Flask con inferencia de Valor y Volatilidad\n",
    "A continuación, el **mismo** código que usas para tu API, pero adaptado para **cargar** el checkpoint local `my_finetuned_timesfm.ckpt`. \n",
    "\n",
    "### NOTA IMPORTANTE\n",
    "Para usar tu nuevo checkpoint en un `TimesFm(...)` real, se requiere la carpeta de `config.json` + `torch_model.ckpt`. Lo más práctico es:\n",
    "1. Descargar la carpeta original del repo HF (snapshot_download), que te da `config.json`, etc.\n",
    "2. Sobrescribir (o renombrar) `torch_model.ckpt` con tu `my_finetuned_timesfm.ckpt`.\n",
    "3. Referenciar `checkpoint=TimesFmCheckpoint(local_path=\"esa/carpeta\")`.\n",
    "\n",
    "Si solo guardas `my_finetuned_timesfm.ckpt` sin la config, tendrás que \"engañar\" a `TimesFmCheckpoint` para que use la config base y tus pesos. \n",
    "Por simplicidad, en la celda de abajo asumimos que tienes una carpeta local, p. ej. `my_fine_repo/` con:\n",
    "- `config.json`\n",
    "- `merges.txt` (si hace falta)\n",
    "- `special_tokens_map.json` (a veces)\n",
    "- `torch_model.ckpt` (este es tu `my_finetuned_timesfm.ckpt` renombrado)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de un 'mini-servicio' Flask con valor y volatilidad.\n",
    "from flask import Flask, Response\n",
    "\n",
    "def create_finetuned_model_service(local_checkpoint_path: str):\n",
    "    \"\"\"\n",
    "    Crea y retorna un Flask con un TimesFM cargado desde 'local_checkpoint_path'.\n",
    "    \"\"\"\n",
    "    app = Flask(__name__)\n",
    "\n",
    "    # Cargamos TimesFm con el checkpoint local\n",
    "    # Asumimos que local_checkpoint_path es una carpeta con config.json y torch_model.ckpt\n",
    "    # en torch_model.ckpt están tus pesos fine-tuneados\n",
    "    global tfm_model\n",
    "\n",
    "    try:\n",
    "        local_ckpt = timesfm.TimesFmCheckpoint(local_path=local_checkpoint_path)\n",
    "        global_hparams = tsfm_hparams  # reusamos el que definimos al principio\n",
    "\n",
    "        tfm_model = timesfm.TimesFm(\n",
    "            hparams=global_hparams,\n",
    "            checkpoint=local_ckpt\n",
    "        )\n",
    "    except:\n",
    "        tfm_model = None\n",
    "\n",
    "    # Reusamos 'prepare_data', 'unscale_value', etc.\n",
    "\n",
    "    @app.route(\"/inference/value/<string:token>/<int:pl>\", methods=[\"GET\"])\n",
    "    def inference_value(token, pl):\n",
    "        try:\n",
    "            if tfm_model is None:\n",
    "                return Response(\"No TimeSFM model loaded\", status=500)\n",
    "            if pl <= 0:\n",
    "                return Response(\"pl>0\", status=400)\n",
    "\n",
    "            df_raw = get_binance_value_5m(token)\n",
    "            if df_raw.empty:\n",
    "                return Response(\"Empty data\", status=500)\n",
    "            df_feat, scalers, _ = prepare_data(df_raw)\n",
    "            if len(df_feat) < 50:\n",
    "                return Response(\"Insufficient data after cleaning\", status=500)\n",
    "\n",
    "            window_size = min(len(df_feat), 512)\n",
    "            tail = df_feat.iloc[-window_size:]\n",
    "            X = tail[\"log_close_scaled\"].values\n",
    "\n",
    "            tfm_model.hparams.horizon_len = pl\n",
    "            with torch.no_grad():\n",
    "                forecast_np = tfm_model.forecast(inputs=[X], freq=[0])\n",
    "            out = forecast_np[0]\n",
    "            if out.ndim == 1:\n",
    "                pred_scaled = out\n",
    "            else:\n",
    "                pred_scaled = out[:, 0]\n",
    "\n",
    "            final_pred_scaled = pred_scaled[-1]\n",
    "            log_c = unscale_value(final_pred_scaled, scalers[\"log_close\"])\n",
    "            price = np.exp(log_c)\n",
    "            if price < 0:\n",
    "                price = 0.0\n",
    "\n",
    "            return Response(f\"{price:.8f}\", status=200)\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())\n",
    "            return Response(str(e), 500)\n",
    "\n",
    "    @app.route(\"/inference/volatility/<string:token>\", methods=[\"GET\"])\n",
    "    def inference_volatility_6h(token):\n",
    "        try:\n",
    "            if tfm_model is None:\n",
    "                return Response(\"No TimeSFM model loaded\", status=500)\n",
    "\n",
    "            df_raw = get_binance_value_5m(token)\n",
    "            if df_raw.empty:\n",
    "                return Response(\"Empty data\", status=500)\n",
    "            df_feat, scalers, _ = prepare_data(df_raw)\n",
    "            if len(df_feat) < 50:\n",
    "                return Response(\"Insufficient data after cleaning\", status=500)\n",
    "\n",
    "            window_size = min(len(df_feat), 512)\n",
    "            tail = df_feat.iloc[-window_size:]\n",
    "            X = tail[\"log_close_scaled\"].values\n",
    "\n",
    "            tfm_model.hparams.horizon_len = 72\n",
    "            with torch.no_grad():\n",
    "                forecast_np = tfm_model.forecast(inputs=[X], freq=[0])\n",
    "            out_np = forecast_np[0]\n",
    "\n",
    "            if out_np.ndim == 1:\n",
    "                scaled_preds = out_np\n",
    "            else:\n",
    "                scaled_preds = out_np[:, 0]\n",
    "\n",
    "            pred_log_close = []\n",
    "            for val_s in scaled_preds:\n",
    "                val_unsc = unscale_value(val_s, scalers[\"log_close\"])\n",
    "                pred_log_close.append(val_unsc)\n",
    "            pred_log_close = np.array(pred_log_close, dtype=np.float32)\n",
    "\n",
    "            if len(pred_log_close) < 2:\n",
    "                hist_log = tail[\"log_close\"].values\n",
    "                if len(hist_log) < 3:\n",
    "                    return Response(\"0.000000\", status=200)\n",
    "                r_hist = hist_log[1:] - hist_log[:-1]\n",
    "                if len(r_hist) < 2:\n",
    "                    return Response(\"0.000000\", status=200)\n",
    "                vol = r_hist.std(ddof=1) * np.sqrt(72.0)\n",
    "                return Response(f\"{vol:.6f}\", status=200)\n",
    "\n",
    "            returns = pred_log_close[1:] - pred_log_close[:-1]\n",
    "            if len(returns) < 2:\n",
    "                return Response(\"0.000000\", status=200)\n",
    "\n",
    "            raw_std = returns.std(ddof=1)\n",
    "            vol_6h = raw_std * np.sqrt(72.0)\n",
    "\n",
    "            if np.isnan(vol_6h) or np.isinf(vol_6h) or vol_6h < 1e-12:\n",
    "                hist_log = tail[\"log_close\"].values\n",
    "                if len(hist_log) < 3:\n",
    "                    vol_6h = 0.0\n",
    "                else:\n",
    "                    r_hist = hist_log[1:] - hist_log[:-1]\n",
    "                    if len(r_hist) < 2:\n",
    "                        vol_6h = 0.0\n",
    "                    else:\n",
    "                        if len(r_hist) >= 72:\n",
    "                            hist_std = r_hist[-72:].std(ddof=1)\n",
    "                        else:\n",
    "                            hist_std = r_hist.std(ddof=1)\n",
    "                        vol_6h = hist_std * np.sqrt(72.0)\n",
    "                        if np.isnan(vol_6h) or np.isinf(vol_6h) or vol_6h < 1e-12:\n",
    "                            vol_6h = 0.0\n",
    "\n",
    "            return Response(f\"{vol_6h:.6f}\", status=200)\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())\n",
    "            return Response(str(e), 500)\n",
    "\n",
    "    return app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución local del Flask\n",
    "Una vez tengas tu carpeta local con `config.json` y `my_finetuned_timesfm.ckpt` (renombrado a `torch_model.ckpt`), puedes crear la app e iniciarla."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ejemplo de cómo lanzar la app\n",
    "# Normalmente lo harías en un main guardado en un .py.\n",
    "\n",
    "# from flask import Flask\n",
    "# if __name__ == \"__main__\":\n",
    "#     local_ckpt_dir = \"./my_finerepo\"  # carpeta con config.json y torch_model.ckpt\n",
    "#     app = create_finetuned_model_service(local_checkpoint_path=local_ckpt_dir)\n",
    "#     app.run(host=\"0.0.0.0\", port=8000, debug=True)\n",
    "# \n",
    "# Luego harías:\n",
    "# GET /inference/value/BTC/10 => predicción a 10 velas\n",
    "# GET /inference/volatility/BTC => volatilidad a 6h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "1. **Ejecuta** la celda de `run_finetuning()` (o llama la función) para entrenar un poco. \n",
    "2. **Reemplaza** `torch_model.ckpt` en una carpeta local con tus pesos generados (`my_finetuned_timesfm.ckpt`). \n",
    "3. **Crea** la app Flask con `create_finetuned_model_service(...)` apuntando a esa carpeta local. \n",
    "4. **Lanza** el servicio y prueba tus endpoints `/inference/value/...` y `/inference/volatility/...`.\n",
    "\n",
    "¡Listo! Has integrado *fine-tuning* de TimeSFM con tu lógica de inferencia de precio y volatilidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}